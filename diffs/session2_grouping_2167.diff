diff --git a/perf_takehome.py b/perf_takehome.py
index f4e9a00..e3f4543 100644
--- a/perf_takehome.py
+++ b/perf_takehome.py
@@ -37,6 +37,116 @@ from problem import (
 )
 
 
+def _vec_range(base: int, length: int = VLEN) -> range:
+    """Helper to get range of vector element addresses."""
+    return range(base, base + length)
+
+
+def _slot_rw(engine: str, slot: tuple) -> tuple[list[int], list[int]]:
+    """Get read and write addresses for a slot (for dependency analysis)."""
+    reads: list[int] = []
+    writes: list[int] = []
+
+    if engine == "alu":
+        _op, dest, a1, a2 = slot
+        reads = [a1, a2]
+        writes = [dest]
+    elif engine == "valu":
+        match slot:
+            case ("vbroadcast", dest, src):
+                reads = [src]
+                writes = list(_vec_range(dest))
+            case ("multiply_add", dest, a, b, c):
+                reads = list(_vec_range(a)) + list(_vec_range(b)) + list(_vec_range(c))
+                writes = list(_vec_range(dest))
+            case (_op, dest, a1, a2):
+                reads = list(_vec_range(a1)) + list(_vec_range(a2))
+                writes = list(_vec_range(dest))
+            case _:
+                raise NotImplementedError(f"Unknown valu op {slot}")
+    elif engine == "load":
+        match slot:
+            case ("load", dest, addr):
+                reads = [addr]
+                writes = [dest]
+            case ("vload", dest, addr):
+                reads = [addr]
+                writes = list(_vec_range(dest))
+            case ("const", dest, _val):
+                writes = [dest]
+            case _:
+                raise NotImplementedError(f"Unknown load op {slot}")
+    elif engine == "store":
+        match slot:
+            case ("store", addr, src):
+                reads = [addr, src]
+            case ("vstore", addr, src):
+                reads = [addr] + list(_vec_range(src))
+            case _:
+                raise NotImplementedError(f"Unknown store op {slot}")
+    elif engine == "flow":
+        match slot:
+            case ("select", dest, cond, a, b):
+                reads = [cond, a, b]
+                writes = [dest]
+            case ("vselect", dest, cond, a, b):
+                reads = list(_vec_range(cond)) + list(_vec_range(a)) + list(_vec_range(b))
+                writes = list(_vec_range(dest))
+            case ("halt",) | ("pause",):
+                pass
+            case _:
+                raise NotImplementedError(f"Unknown flow op {slot}")
+
+    return reads, writes
+
+
+def _schedule_slots(slots: list[tuple[str, tuple]]) -> list[dict[str, list[tuple]]]:
+    """Automatically schedule operations into VLIW bundles respecting dependencies."""
+    cycles: list[dict[str, list[tuple]]] = []
+    usage: list[dict[str, int]] = []
+    ready_time: dict[int, int] = defaultdict(int)
+    last_write: dict[int, int] = defaultdict(lambda: -1)
+    last_read: dict[int, int] = defaultdict(lambda: -1)
+
+    def ensure_cycle(cycle: int) -> None:
+        while len(cycles) <= cycle:
+            cycles.append({})
+            usage.append(defaultdict(int))
+
+    def find_cycle(engine: str, earliest: int) -> int:
+        cycle = earliest
+        limit = SLOT_LIMITS[engine]
+        while True:
+            ensure_cycle(cycle)
+            if usage[cycle][engine] < limit:
+                return cycle
+            cycle += 1
+
+    for engine, slot in slots:
+        if engine == "debug":
+            continue  # Skip debug instructions
+        reads, writes = _slot_rw(engine, slot)
+        earliest = 0
+        for addr in reads:
+            earliest = max(earliest, ready_time[addr])
+        for addr in writes:
+            earliest = max(earliest, last_write[addr] + 1, last_read[addr])
+
+        cycle = find_cycle(engine, earliest)
+        ensure_cycle(cycle)
+        cycles[cycle].setdefault(engine, []).append(slot)
+        usage[cycle][engine] += 1
+
+        for addr in reads:
+            if last_read[addr] < cycle:
+                last_read[addr] = cycle
+        for addr in writes:
+            last_write[addr] = cycle
+            ready_time[addr] = cycle + 1
+
+    return [c for c in cycles if c]
+
+
 class KernelBuilder:
     def __init__(self):
         self.instrs = []
@@ -44,6 +154,7 @@ class KernelBuilder:
         self.scratch_debug = {}
         self.scratch_ptr = 0
         self.const_map = {}
+        self.vconst_map = {}
 
     def debug_info(self):
         return DebugInfo(scratch_map=self.scratch_debug)
@@ -67,13 +178,32 @@ class KernelBuilder:
         assert self.scratch_ptr <= SCRATCH_SIZE, "Out of scratch space"
         return addr
 
-    def scratch_const(self, val, name=None):
+    def scratch_const(self, val, name=None, slots=None):
         if val not in self.const_map:
             addr = self.alloc_scratch(name)
-            self.add("load", ("const", addr, val))
+            if slots is None:
+                self.add("load", ("const", addr, val))
+            else:
+                slots.append(("load", ("const", addr, val)))
             self.const_map[val] = addr
         return self.const_map[val]
 
+    def alloc_vec(self, name=None):
+        """Allocate a vector (VLEN elements) in scratch."""
+        return self.alloc_scratch(name, VLEN)
+
+    def scratch_vconst(self, val, name=None, slots=None):
+        """Allocate and broadcast a constant to a vector."""
+        if val not in self.vconst_map:
+            scalar = self.scratch_const(val, slots=slots)
+            addr = self.alloc_vec(name)
+            if slots is None:
+                self.add("valu", ("vbroadcast", addr, scalar))
+            else:
+                slots.append(("valu", ("vbroadcast", addr, scalar)))
+            self.vconst_map[val] = addr
+        return self.vconst_map[val]
+
     def build_hash(self, val_hash_addr, tmp1, tmp2, round, i):
         slots = []
 
@@ -86,91 +216,160 @@ class KernelBuilder:
         return slots
 
     def build_kernel(
-        self, forest_height: int, n_nodes: int, batch_size: int, rounds: int
+        self, forest_height: int, n_nodes: int, batch_size: int, rounds: int,
+        group_size: int = 16
     ):
         """
-        Like reference_kernel2 but building actual instructions.
-        Scalar implementation using only scalar ALU and load/store.
+        Vectorized kernel with group-based processing for better pipelining.
+
+        Key optimization: Process multiple blocks (group_size) together so that
+        when one block is doing VALU ops, another can do gather loads.
+        This improves utilization of both load (2 slots) and valu (6 slots) engines.
         """
-        tmp1 = self.alloc_scratch("tmp1")
-        tmp2 = self.alloc_scratch("tmp2")
-        tmp3 = self.alloc_scratch("tmp3")
-        # Scratch space addresses
+        # Scalar temporaries
+        tmp_addr = self.alloc_scratch("tmp_addr")
+        tmp_addr2 = self.alloc_scratch("tmp_addr2")
+        tmp_scalar = self.alloc_scratch("tmp_scalar")
+
+        # Initialize from memory header
         init_vars = [
-            "rounds",
-            "n_nodes",
-            "batch_size",
-            "forest_height",
-            "forest_values_p",
-            "inp_indices_p",
-            "inp_values_p",
+            "rounds", "n_nodes", "batch_size", "forest_height",
+            "forest_values_p", "inp_indices_p", "inp_values_p",
         ]
         for v in init_vars:
             self.alloc_scratch(v, 1)
-        for i, v in enumerate(init_vars):
-            self.add("load", ("const", tmp1, i))
-            self.add("load", ("load", self.scratch[v], tmp1))
-
-        zero_const = self.scratch_const(0)
-        one_const = self.scratch_const(1)
-        two_const = self.scratch_const(2)
 
-        # Pause instructions are matched up with yield statements in the reference
-        # kernel to let you debug at intermediate steps. The testing harness in this
-        # file requires these match up to the reference kernel's yields, but the
-        # submission harness ignores them.
+        init_slots = []
+        for i, v in enumerate(init_vars):
+            init_slots.append(("load", ("const", tmp_scalar, i)))
+            init_slots.append(("load", ("load", self.scratch[v], tmp_scalar)))
+
+        # Vector constants
+        zero_vec = self.scratch_vconst(0, "v_zero", init_slots)
+        one_vec = self.scratch_vconst(1, "v_one", init_slots)
+        two_vec = self.scratch_vconst(2, "v_two", init_slots)
+        one_const = self.scratch_const(1, slots=init_slots)
+
+        # Broadcast forest_values_p to vector for address calculation
+        forest_vec = self.alloc_vec("v_forest_p")
+        init_slots.append(("valu", ("vbroadcast", forest_vec, self.scratch["forest_values_p"])))
+
+        # Broadcast n_nodes to vector for comparison
+        n_nodes_vec = self.alloc_vec("v_n_nodes")
+        init_slots.append(("valu", ("vbroadcast", n_nodes_vec, self.scratch["n_nodes"])))
+
+        # Hash constants (vectorized)
+        hash_vec_consts1 = []
+        hash_vec_consts3 = []
+        for op1, val1, op2, op3, val3 in HASH_STAGES:
+            hash_vec_consts1.append(self.scratch_vconst(val1, slots=init_slots))
+            hash_vec_consts3.append(self.scratch_vconst(val3, slots=init_slots))
+
+        # Schedule init phase
+        self.instrs.extend(_schedule_slots(init_slots))
         self.add("flow", ("pause",))
-        # Any debug engine instruction is ignored by the submission simulator
-        self.add("debug", ("comment", "Starting loop"))
-
-        body = []  # array of slots
-
-        # Scalar scratch registers
-        tmp_idx = self.alloc_scratch("tmp_idx")
-        tmp_val = self.alloc_scratch("tmp_val")
-        tmp_node_val = self.alloc_scratch("tmp_node_val")
-        tmp_addr = self.alloc_scratch("tmp_addr")
 
-        for round in range(rounds):
-            for i in range(batch_size):
-                i_const = self.scratch_const(i)
-                # idx = mem[inp_indices_p + i]
-                body.append(("alu", ("+", tmp_addr, self.scratch["inp_indices_p"], i_const)))
-                body.append(("load", ("load", tmp_idx, tmp_addr)))
-                body.append(("debug", ("compare", tmp_idx, (round, i, "idx"))))
-                # val = mem[inp_values_p + i]
-                body.append(("alu", ("+", tmp_addr, self.scratch["inp_values_p"], i_const)))
-                body.append(("load", ("load", tmp_val, tmp_addr)))
-                body.append(("debug", ("compare", tmp_val, (round, i, "val"))))
-                # node_val = mem[forest_values_p + idx]
-                body.append(("alu", ("+", tmp_addr, self.scratch["forest_values_p"], tmp_idx)))
-                body.append(("load", ("load", tmp_node_val, tmp_addr)))
-                body.append(("debug", ("compare", tmp_node_val, (round, i, "node_val"))))
-                # val = myhash(val ^ node_val)
-                body.append(("alu", ("^", tmp_val, tmp_val, tmp_node_val)))
-                body.extend(self.build_hash(tmp_val, tmp1, tmp2, round, i))
-                body.append(("debug", ("compare", tmp_val, (round, i, "hashed_val"))))
-                # idx = 2*idx + (1 if val % 2 == 0 else 2)
-                body.append(("alu", ("%", tmp1, tmp_val, two_const)))
-                body.append(("alu", ("==", tmp1, tmp1, zero_const)))
-                body.append(("flow", ("select", tmp3, tmp1, one_const, two_const)))
-                body.append(("alu", ("*", tmp_idx, tmp_idx, two_const)))
-                body.append(("alu", ("+", tmp_idx, tmp_idx, tmp3)))
-                body.append(("debug", ("compare", tmp_idx, (round, i, "next_idx"))))
-                # idx = 0 if idx >= n_nodes else idx
-                body.append(("alu", ("<", tmp1, tmp_idx, self.scratch["n_nodes"])))
-                body.append(("flow", ("select", tmp_idx, tmp1, tmp_idx, zero_const)))
-                body.append(("debug", ("compare", tmp_idx, (round, i, "wrapped_idx"))))
-                # mem[inp_indices_p + i] = idx
-                body.append(("alu", ("+", tmp_addr, self.scratch["inp_indices_p"], i_const)))
-                body.append(("store", ("store", tmp_addr, tmp_idx)))
-                # mem[inp_values_p + i] = val
-                body.append(("alu", ("+", tmp_addr, self.scratch["inp_values_p"], i_const)))
-                body.append(("store", ("store", tmp_addr, tmp_val)))
-
-        body_instrs = self.build(body)
-        self.instrs.extend(body_instrs)
-        # Required to match with the yield in reference_kernel2
+        # Main body
+        assert batch_size % VLEN == 0
+        n_blocks = batch_size // VLEN
+
+        # Allocate scratch for all idx/val vectors (persistent across rounds)
+        idx_base = self.alloc_scratch("idx_scratch", batch_size)
+        val_base = self.alloc_scratch("val_scratch", batch_size)
+
+        # Allocate context for each block in a group (separate tmp registers)
+        # This allows interleaved execution without data hazards
+        contexts = []
+        for g in range(group_size):
+            contexts.append({
+                "node": self.alloc_vec(f"node_{g}"),
+                "tmp1": self.alloc_vec(f"tmp1_{g}"),
+                "tmp2": self.alloc_vec(f"tmp2_{g}"),
+            })
+
+        slots: list[tuple[str, tuple]] = []
+
+        # Load initial idx/val from memory
+        vlen_const = self.scratch_const(VLEN, slots=slots)
+        offset = self.alloc_scratch("offset")
+        slots.append(("load", ("const", offset, 0)))
+
+        for block in range(n_blocks):
+            # Load idx vector
+            slots.append(("alu", ("+", tmp_addr, self.scratch["inp_indices_p"], offset)))
+            slots.append(("load", ("vload", idx_base + block * VLEN, tmp_addr)))
+            # Load val vector
+            slots.append(("alu", ("+", tmp_addr, self.scratch["inp_values_p"], offset)))
+            slots.append(("load", ("vload", val_base + block * VLEN, tmp_addr)))
+            # Increment offset
+            slots.append(("alu", ("+", offset, offset, vlen_const)))
+
+        # Process blocks in groups for better interleaving
+        for group_start in range(0, n_blocks, group_size):
+            group_end = min(group_start + group_size, n_blocks)
+            actual_group_size = group_end - group_start
+
+            # Process all rounds for this group, interleaving blocks
+            for rnd in range(rounds):
+                # Generate operations for all blocks in group
+                for gi in range(actual_group_size):
+                    block = group_start + gi
+                    ctx = contexts[gi]
+                    idx_vec = idx_base + block * VLEN
+                    val_vec = val_base + block * VLEN
+
+                    # Gather node values: compute addresses
+                    for lane in range(VLEN):
+                        slots.append(("alu", ("+", ctx["tmp1"] + lane, forest_vec + lane, idx_vec + lane)))
+
+                # Interleaved loads - all blocks' gathers together
+                for gi in range(actual_group_size):
+                    block = group_start + gi
+                    ctx = contexts[gi]
+                    for lane in range(VLEN):
+                        slots.append(("load", ("load", ctx["node"] + lane, ctx["tmp1"] + lane)))
+
+                # VALU operations for all blocks (can overlap with next group's loads)
+                for gi in range(actual_group_size):
+                    block = group_start + gi
+                    ctx = contexts[gi]
+                    idx_vec = idx_base + block * VLEN
+                    val_vec = val_base + block * VLEN
+
+                    # val = val ^ node_val
+                    slots.append(("valu", ("^", val_vec, val_vec, ctx["node"])))
+
+                    # Hash computation (6 stages)
+                    for hi, (op1, val1, op2, op3, val3) in enumerate(HASH_STAGES):
+                        slots.append(("valu", (op1, ctx["tmp1"], val_vec, hash_vec_consts1[hi])))
+                        slots.append(("valu", (op3, ctx["tmp2"], val_vec, hash_vec_consts3[hi])))
+                        slots.append(("valu", (op2, val_vec, ctx["tmp1"], ctx["tmp2"])))
+
+                    # idx = 2*idx + (1 if val%2==0 else 2)
+                    slots.append(("valu", ("&", ctx["tmp1"], val_vec, one_vec)))
+                    slots.append(("valu", ("==", ctx["tmp1"], ctx["tmp1"], zero_vec)))
+                    slots.append(("flow", ("vselect", ctx["tmp2"], ctx["tmp1"], one_vec, two_vec)))
+                    slots.append(("valu", ("*", idx_vec, idx_vec, two_vec)))
+                    slots.append(("valu", ("+", idx_vec, idx_vec, ctx["tmp2"])))
+
+                    # idx = 0 if idx >= n_nodes else idx
+                    slots.append(("valu", ("<", ctx["tmp1"], idx_vec, n_nodes_vec)))
+                    slots.append(("flow", ("vselect", idx_vec, ctx["tmp1"], idx_vec, zero_vec)))
+
+        # Store final results
+        slots.append(("load", ("const", offset, 0)))
+        for block in range(n_blocks):
+            # Store val vector
+            slots.append(("alu", ("+", tmp_addr, self.scratch["inp_values_p"], offset)))
+            slots.append(("store", ("vstore", tmp_addr, val_base + block * VLEN)))
+            # Store idx vector
+            slots.append(("alu", ("+", tmp_addr, self.scratch["inp_indices_p"], offset)))
+            slots.append(("store", ("vstore", tmp_addr, idx_base + block * VLEN)))
+            # Increment offset
+            slots.append(("alu", ("+", offset, offset, vlen_const)))
+
+        # Schedule all body operations
+        self.instrs.extend(_schedule_slots(slots))
         self.instrs.append({"flow": [("pause",)]})
 
 BASELINE = 147734
